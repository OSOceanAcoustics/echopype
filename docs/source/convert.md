(convert)=
# Convert raw files

(convert-sonar_types)=
## Supported raw file types

Echopype supports converting raw instrument-generated data files into [netCDF](https://www.unidata.ucar.edu/software/netcdf/) or [Zarr](https://zarr.readthedocs.io) from the following echosounders:
- `.raw` files generated by [Kongsberg Simrad](https://www.kongsberg.com/maritime/contact/simrad/) EK60, ES70, EK80, and ES80 echosounders and Kongsberg EA640 echosounder
- `.01A` files generated by [ASL Environmental Sciences](https://aslenv.com) AZFP echosounder
- `.ad2cp` files generated by [Nortek](https://www.nortekgroup.com/) Signature series Acoustic Doppler Current Profilers (ADCPs) (beta)


## Conversion operation

File conversion for different types of echosounders is achieved by using the function `open_raw` to parse the raw data and create an `EchoData` object.

Use the parameter `sonar_model` to indicate the echosounder model:
- `EK60`: Kongsberg Simrad EK60 echosounder
- `ES70`: Kongsberg Simrad ES70 echosounder
- `EK80`: Kongsberg Simrad EK80 echosounder
- `ES80`: Kongsberg Simrad ES80 echosounder
- `EA640`: Kongsberg EA640 echosounder
- `AZFP`: ASL Environmental Sciences AZFP echosounder
- `AD2CP`: Nortek Signature series ADCP (tested with Signature 500 and Signature 1000 files collected in 2021)


To convert a raw EK80 file to an in-memory `EchoData` object and save it to a netCDF or zarr file:
```python
import echopype as ep  # we encourage importing echopype as ep

ed = ep.open_raw("FILENAME.raw", sonar_model="EK80")  # for EK80 file
ed.to_netcdf(save_path="./unpacked_files")  # save to FILENAME.nc in the folder unpacked_files
ed.to_zarr(save_path="./unpacked_files/NEW_FILENAME.zarr")  # fully specify filename also works
```

For data from the AZFP echosounder, the conversion requires an extra `.XML` file (specified using `xml_path`) along with the `.01A` data file:

```python
ed = open_raw("FILENAME.01A", sonar_model="AZFP", xml_path="XML_FILENAME.xml")  # AZFP data need an XML file
ed.to_netcdf(save_path="./unpacked_files")
```

The AZFP `.XML` file contains a lot of metadata needed for unpacking the binary `.01A` files. Typically a single `.XML` file is associated with all files from the same deployment.

:::{tip}
The `EchoData` object contains all the data unpacked from the raw file, so it is a good idea to clear it from memory once done with conversion.
:::

:::{attention}
In Echopype v0.6.2 we improved `open_raw` by allowing users to directly write variables that may consume a large amount of memory into a temporary zarr store ([#774](https://github.com/OSOceanAcoustics/echopype/pull/774)).

This feature is accessible through `open_raw` via arguments `use_swap` and `max_mb` and is only available for the following echosounders: EK60, ES70, EK80, ES80, EA640. See the [API reference](api-open_raw) for usage.
:::


## File access

### Local and remote file sources

<!-- .. ``open_raw`` can accept a list of file paths pointing to multiple files.
.. For example:

.. .. code-block:: python

   raw_file_paths = [
      './raw_data_files/file_01.raw',
      './raw_data_files/file_02.raw'
   ]
   ed = open_raw(raw_file_paths, sonar_model='EK60') -->

`open_raw` can accept paths to files on both local and remote file systems (e.g., web `http` server and cloud object storage such as Amazon Web Services (AWS) S3).
This capability is provided by the [fsspec](https://filesystem-spec.readthedocs.io) package, and all file systems implemented by `fsspec` are supported (see the list [here](https://filesystem-spec.readthedocs.io/en/latest/api.html#built-in-implementations)).


For a file on a web server can be accessed by specifying the file url:
```python
ed = open_raw(
    "https://mydomain.com/my/dir/D20170615-T190214.raw",  # file on http server
    sonar_model="EK80"
)
```

For a file in a publicly accessible S3 bucket:
```python
raw_file_s3path = "s3://mybucket/my/dir/D20170615-T190214.raw"
ed = open_raw(
    "s3://mybucket/my/dir/D20170615-T190214.raw",  # file in S3 bucket
    sonar_model="EK80",
    storage_options={"anon": True}  # publicly accessible file ("anonymous")
)
```

For a file in a private S3 bucket:
```python
raw_file_s3path = "s3://mybucket/my/dir/D20170615-T190214.raw"
ed = open_raw(
    "s3://mybucket/my/dir/D20170615-T190214.raw",  # file in S3 bucket
    sonar_model="EK80",
    storage_options={"key": "ACCESSKEY", "secret": "SECRETKEY"}  # access credentials
)
```

It is often safer to store a credential file so that the access credentials are not supplied directly in scripts or notebooks. For example, for AWS, a default AWS credentials file
(`~/.aws/credentials`) can contain a with `profile` "myprofilename" and be used with `aiobotocore` to access data:
```python
import aiobotocore
aws_session = aiobotocore.AioSession(profile="myprofilename")
ed = open_raw(
    raw_file_s3path, sonar_model="EK60",
    storage_options={"session": aws_session}
)
```


File export
-----------

Converted data are saved to netCDF4 or Zarr files using ``EchoData.to_netcdf()``
and ``EchoData.to_zarr()``. These methods accept convenient optional arguments.
The examples below apply equally to both methods, except as noted.

A destination folder or file path should be specified with the ``save_path``
argument in these methods in order to control the location of the converted files.
If the argument is not specified, the converted ``.nc`` and ``.zarr``
files are saved into the directory ``~/.echopype/temp_output``.
This folder will be created if it doesn't already exists.


Specify metadata attributes
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Before calling ``to_netcdf()`` or ``to_zarr()``, you can manually set some
metadata attributes that are not recorded in the raw data files but need to be
specified according to the SONAR-netCDF4 convention.
Common attributes typically not found in the raw files include the following,
in the ``Platform`` netCDF4 group:
``platform_name``, ``platform_type`` and ``platform_code_ICES``.
These attributes can be set using the following:

.. code-block:: python

    ed['Platform']['platform_name'] = 'OOI'
    ed['Platform']['platform_type'] = 'subsurface mooring'
    ed['Platform']['platform_code_ICES'] = '3164'   # Platform code for Moorings

The ``platform_code_ICES`` attribute can be chosen by referencing
the platform code from the
`ICES SHIPC vocabulary <https://vocab.ices.dk/?ref=315>`_.


.. Save converted files into a specified folder
.. ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. In this example, each input file will be converted to an individual ``.nc`` file
.. and stored in the ``./unpacked_files`` directory.

.. .. code-block:: python

   raw_file_paths = [                              # a list of raw data files
      './raw_data_files/dir1/file_01.raw',
      './raw_data_files/dir2/file_02.raw'
   ]
   ed = open_raw(raw_file_paths, sonar_model='EK60')     # create an EchoData object
   ed.to_netcdf(save_path='./unpacked_files')      # set the output directory

.. Combine multiple raw files into one converted file
.. ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. Multiple files can be combined into a single converted file using the
.. ``combine`` argument (the default is ``combine=False``). In that case,
.. ``save_path`` must be specified explicitly. If ``save_path`` is only a filename
.. rather than a full file path, the combined output file will be saved to the
.. default ``~/.echopype/temp_output`` folder.

.. .. code-block:: python

   raw_file_paths = [                              # a list of raw data files
      './raw_data_files/dir1/file_01.raw',
      './raw_data_files/dir2/file_02.raw'
   ]
   ed = open_raw(raw_file_paths, sonar_model='EK60')     # create an EchoData object
   ed.to_zarr(
      combine=True,                                # combine all input files on conversion
      save_path='./unpacked_files/combined_file.zarr'
   )

Save to AWS S3
~~~~~~~~~~~~~~

.. note::

   These instructions should apply to other object storage providers such as
   Google Cloud and Azure, but have only been tested on AWS S3.

Converted files can be saved directly into an AWS S3 bucket by specifying
``output_storage_options``, similar to ``storage_options`` with input files
(see above, "AWS S3 access"). The example below illustrates a fully remote
processing pipeline, reading a raw file from a web server and saving the
converted Zarr dataset to S3. (As with ``storage_options`` when accessing
raw data from S3, a ``profile``-based ``session`` can also be used, passing the
``session`` to ``output_storage_options``). Writing netCDF4 to S3 is
currently not supported.

.. code-block:: python

      raw_file_url = 'http://mydomain.com/from1/file_01.raw'
      ed = open_raw(raw_file_url, sonar_model='EK60')
      ed.to_zarr(
         overwrite=True,
         save_path='s3://mybucket/converted_file.zarr',
         output_storage_options={'key': 'ACCESSKEY', 'secret': 'SECRETKEY'}
      )

.. note::

   Zarr datasets will be automatically chunked with default chunk sizes of
   25000 for ``range_sample`` and 2500 for ``ping_time`` dimensions.
