Convert raw files
=================

Supported raw file types
------------------------

Echopype currently supports conversion into 
`netCDF4 <https://www.unidata.ucar.edu/software/netcdf/>`_ or 
`Zarr <https://zarr.readthedocs.io>`_ files from these raw formats:

- ``.raw`` files generated by `Kongsberg-Simrad <https://www.kongsberg.com/maritime/contact/simrad/>`_'s 
  EK60 and EK80 echosounders and Kongsberg's EA640 echosounder
- ``.01A`` files generated by `ASL Environmental Sciences <https://aslenv.com>`_' AZFP echosounder

Support for conversion of beam intensity data from Acoustic Doppler Current Profilers (ADCPs)
is currently under development.

Importing echopype
------------------

We encourage importing the ``echopype`` package with the alias ``ep``:

.. code-block:: python

    import echopype as ep

In the examples below, we import ``open_raw`` as follows:

.. code-block:: python

    from echopype import open_raw

Conversion operation
--------------------

File conversion for different types of echosounders is achieved by
using the single function ``open_raw``.

For data files from EK60, EK80 and  EA640 echosounders,
use the parameter ``model`` to indicate the echosounder type,
since there is no specific information in the extension ``.raw``
that includes information about the echosounder type:

.. code-block:: python

    ed = open_raw('FILENAME.raw', model='EK80')  # for EK80 file
    ed.to_netcdf(save_path='./unpacked_files')

This will generate a ``FILENAME.nc`` file and save it to the 
``./unpacked_files`` folder.


.. EXPERIMENT WITH BEST WAY TO PRESENT NOTES (DIRECTIVES) ABOUT CHANGES WITH NEW VERSION

.. attention::

   - Prior to version 0.5.0, conversion was carried out through the
     `"Convert" interface <https://echopype.readthedocs.io/en/latest/usage.html#conversion-operation>`_.
     This interface is still available but will be deprecated in 
     a future version.
   - Versions of echopype prior to 0.5.0 used ``raw2nc`` and ``raw2zarr``
     in order to convert to netCDF4 or Zarr files respectively. 
     These methods have been renamed to ``to_netcdf`` and ``to_zarr``
     and the old names will be deprecated in a future version.

**TODO:** 

- Briefly state that open_raw returns an EchoData object (note that an EchoData class has
  existed in echopype for a while, but it's been overhauled and made more user-facing in 0.5.0);
  link to the page/section where it's described in more detail.
- Does open_raw fully open and parse the raw data eagerly, or lazily/delayed?
  Once I confirm which is it, mention it briefly.
- Add some sample code for interacting with the parsed EchoData object in memory

For data files from the AZFP echosounder, the conversion requires an
extra ``.XML`` file along with the ``.01A`` data file, specified using
the parameter ``xml_path``:

.. code-block:: python

    ed = open_raw('FILENAME.01A', model='AZFP', xml_path='XMLFILENAME.xml')
    ed.to_netcdf(save_path='./unpacked_files')

The ``.XML`` file contains a lot of metadata needed for unpacking the 
binary data files. Typically a single ``.XML`` file is associated with 
all files from the same deployment.

.. note::

   The ``EchoData`` instance contains all the data unpacked from the raw file,
   so it is a good idea to clear it from memory once done with conversion.


File access
-----------

Specifying multiple files
~~~~~~~~~~~~~~~~~~~~~~~~~

``open_raw`` can accept a list of file paths pointing to multiple files. 
For example:

.. code-block:: python

   raw_file_paths = [
      './raw_data_files/file_01.raw',
      './raw_data_files/file_02.raw'
   ]
   ed = open_raw(raw_file_paths, model='EK60')

``open_raw`` can also accept paths to files on remote systems such as ``http`` 
(a file on a web server) and cloud object storage such as Amazon Web Services (AWS) S3. 
This capability is provided by the `fsspec <https://filesystem-spec.readthedocs.io>`_ 
package, and all file systems implemented by ``fsspec`` are supported; 
a list of these file systems is available on the 
`fsspec registry documentation <https://filesystem-spec.readthedocs.io/en/latest/api.html#built-in-implementations>`_.

.. warning::
   ``fsspec``-based access from file locations other than a local file system was 
   introduced in version 0.5.0

https access
~~~~~~~~~~~~

A file on a web server can be accessed by specifying the file url:

.. code-block:: python

   raw_file_url = "https://mydomain.com/my/dir/D20170615-T190214.raw"
   ed = open_raw(raw_file_url, model='EK60')

AWS S3 access
~~~~~~~~~~~~~

.. note::

   These instructions should apply to other object storage providers such as 
   Google Cloud and Azure, but have only been tested on AWS S3.

A file on an `AWS S3 <https://aws.amazon.com/s3/>`_ "bucket" can be accessed by 
specifying the S3 path that starts with "s3://" and using the ``storage_options`` 
argument. For a publicly accessible file ("anonymous") on a bucket called ``mybucket``:

.. code-block:: python

   raw_file_s3path = "s3://mybucket/my/dir/D20170615-T190214.raw"
   ed = open_raw(
      raw_file_s3path, model='EK60', 
      storage_options={'anon': True}
   )

If the file is not publicly accessible, the credentials can be specified explicitly
through ``storage_options`` keywords:

.. code-block:: python

   ed = open_raw(
      raw_file_s3path, model='EK60', 
      storage_options={key: 'ACCESSKEY', secret: 'SECRETKEY'}
   )

or via a credentials file stored in the default AWS credentials file 
(``~/.aws/credentials``). For ``profile`` "myprofilename" found in 
the credential file:

.. code-block:: python

   import aiobotocore
   aws_session = aiobotocore.AioSession(profile='myprofilename')
   ed = open_raw(
      raw_file_s3path, model='EK60', 
      storage_options={'session': aws_session}
   )


File export
-----------

Converted data are saved to netCDF4 or Zarr files using ``EchoData.to_netcdf()`` 
and ``EchoData.to_zarr()``. These methods accept convenient optional arguments. 
The examples below apply equally to both methods, except as noted.

A destination folder or file path should be specified with the ``save_path`` 
argument in these methods in order to control the location of the converted files.
If the argument is not specified, the converted ``.nc`` and ``.zarr`` 
files are saved into a folder called ``temp_echopype_output`` under the 
current execution folder. This folder will be created if it doesn't already exists.

.. warning::

   The use of a default ``temp_echopype_output`` folder was introduced in 
   versions 0.5.0. In prior versions, the default was to save each
   converted file into the same folder as the corresponding input file.

Specify platform and water level attributes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Before calling ``to_netcdf()`` or ``to_zarr()``, you should first set 
``platform_name``, ``platform_type``, and ``platform_code_ICES``, as these values
are not recorded in the raw data files but need to be specified according to the 
SONAR-netCDF4 convention. These parameters will be saved as empty strings unless 
you specify them following this example:

.. code-block:: python

    ed.platform_name = 'OOI'
    ed.platform_type = 'subsurface mooring'
    ed.platform_code_ICES = '3164'   # Platform code for Moorings

The ``platform_code_ICES`` attribute can be chosen by referencing
the platform code from the
`ICES SHIPC vocabulary <https://vocab.ices.dk/?ref=315>`_.

The water level should be specified using ``ed.water_level = 'some value'``
if the value is known. Otherwise, the water level will be saved as
``None`` if it is not already recorded by the instrument.

Save converted files into a specified folder
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In this example, each input file will be converted to an individual ``.nc`` file
and stored in the ``./unpacked_files`` directory.

.. code-block:: python

   raw_file_paths = [                              # a list of raw data files
      './raw_data_files/dir1/file_01.raw',
      './raw_data_files/dir2/file_02.raw'
   ]
   ed = open_raw(raw_file_paths, model='EK60')     # create an EchoData object
   ed.to_netcdf(save_path='./unpacked_files')      # set the output directory

Combine multiple raw files into one converted file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Multiple files can be combined into a single converted file using the
``combine`` argument (the default is ``combine=False``). In that case,
``save_path`` must be specified explicitly. If ``save_path`` is only a filename 
rather than a full file path, the combined output file will be saved to the
default ``temp_echopype_output`` folder.

.. code-block:: python

   raw_file_paths = [                              # a list of raw data files
      './raw_data_files/dir1/file_01.raw',
      './raw_data_files/dir2/file_02.raw'
   ]
   ed = open_raw(raw_file_paths, model='EK60')     # create an EchoData object
   ed.to_zarr(
      combine=True,                                # combine all input files on conversion
      save_path='./unpacked_files/combined_file.zarr'
   )

Save to AWS S3
~~~~~~~~~~~~~~

.. note::

   These instructions should apply to other object storage providers such as 
   Google Cloud and Azure, but have only been tested on AWS S3.

.. warning::
   Saving to S3 was introduced in version 0.5.0.

Converted files can be saved directly into an AWS S3 bucket by specifying ``storage_options``
as done with input files (see above, "AWS S3 access"). The example below illustrates a 
fully remote processing pipeline, reading raw files from a web server and saving the converted, 
combined zarr dataset to S3. Writing netCDF4 to S3 is currently not supported.

**TODO:** Add information about how to specify chunking and what the default chunking scheme is.

.. code-block:: python

      raw_file_urls = [
         'http://mydomain.com/from1/file_01.raw',
         'http://mydomain.com/from2/file_02.raw'
      ]
      ed = open_raw(raw_file_urls, model='EK60')
      ed.to_zarr(
         combine=True,
         overwrite=True,
         save_path='s3://mybucket/to/combined_file.zarr',
         storage_options={key: 'ACCESSKEY', secret: 'SECRETKEY'}
      )


Non-uniform data
----------------

Due to flexibility in echosounder settings, some dimensional parameters can
change in the middle of the file. For example:

- The maximum depth range to which data are collected can change in the middle
  of a data file in EK60. This happens often when the bottom depth changes.
- The sampling interval, which translates to temporal resolution, and thus range
  resolution, can also change in the middle of the file.
- Data from different frequency channels can also be collected with
  different sampling intervals.

These changes produce different number of samples along range (the ``range_bin``
dimension in the converted ``.nc`` file), which are incompatible with the goal
to save the data as a multi-dimensional array that can be easily indexed using xarray.

Echopype accommodates these cases in the following two ways:

1. When there are changes in the ``range_bin`` dimension in the middle of
   a data file, echopype creates separate files for each consecutive chunk of
   data with the same number of samples along range and append ``_partXX`` to
   the converted filename to indicate the existence of such changes.
   For example, if ``datafile.raw`` contains changes in the number of
   samples along range, the converted output will be ``datafile_part01.nc``,
   ``datafile_part02.nc``, etc.

2. When the number of samples along the ``range_bin`` dimensions are different
   for different frequency channels, echopype pads the shorter channels with
   ``NaN`` to form a multi-dimensional array. We use the data compression option
   in ``xarray.to_netcdf()`` and ``xarray.to_zarr()`` to avoid dramatically
   increasing the output file size due to padding.
