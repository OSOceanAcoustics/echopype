Convert raw files
=================

Supported file types
--------------------

Echopype currently supports conversion from

- ``.raw`` files generated by `Kongsberg-Simrad <https://www.kongsberg.com/maritime/contact/simrad/>`_'s 
  EK60 and EK80 echosounders and Kongsberg's EA640 echosounder
- ``.01A`` files generated by `ASL Environmental Sciences <https://aslenv.com>`_' AZFP echosounder

into `netCDF <https://www.unidata.ucar.edu/software/netcdf/>`_ (stable) or 
`Zarr <https://zarr.readthedocs.io>`_ (beta) files.

We are planning on adding conversion and calibration routines for
beam intensity data from Acoustic Doppler Current Profilers (ADCPs).

.. _creating issues on GitHub:
   https://medium.com/nyc-planning-digital/writing-a-proper-github-issue-97427d62a20f
.. _Pull requests:
   https://jarednielsen.com/learn-git-fork-pull-request/

In the examples below, the ``echopype`` package will be imported as follows:

.. code-block:: python

    import echopype as ep


Conversion operation
--------------------

File conversion for different types of echosounders is achieved by
using a single interface through the ``Convert`` subpackage.

For data files from EK60, EK80 and  EA640 echosounders,
use the parameter ``model`` to indicate the echosounder type,
since there is no specific information in the extension ``.raw``
that include information about the echosounder type:

.. code-block:: python

    dc = ep.Convert('FILENAME.raw', model='EK80')  # for EK80 file
    dc.to_netcdf()

This will generate a ``FILENAME.nc`` file in the same directory as
the original ``FILENAME.raw`` file.

.. warning::
   Versions of echopype prior to 0.5.0 used ``raw2nc`` and ``raw2zarr``
   in order to convert to netCDF or Zarr files respectively. These methods have
   been renamed to ``to_netcdf`` and ``to_zarr``.

For data files from the AZFP echosounder, the conversion requires an
extra ``.XML`` file along with the ``.01A`` data file. The ``.XML`` file
contains a lot of metadata needed for unpacking the binary data files.
Typically one single ``.XML`` file is associated with all files from the
same deployment. This can be done by:

.. code-block:: python

    dc = ep.Convert('FILENAME.01A', model='AZFP', xml_path='XMLFILENAME.xml')
    dc.to_netcdf()

Before calling ``to_netcdf()`` or ``to_zarr()`` to create netCDF or Zarr
files, you should first set ``platform_name``, ``platform_type``, and
``patform_code_ICES``, as these values are not recorded in the raw data
files but need to be specified according to the SONAR-netCDF4 convention.
These parameters will be saved as empty strings unless you specify
them following the example below:

.. code-block:: python

    dc.platform_name = 'OOI'
    dc.platform_type = 'subsurface mooring'
    dc.platform_code_ICES = '3164'   # Platform code for Moorings

The ``platform_code_ICES`` attribute can be chosen by referencing
the platform code from the
`ICES SHIPC vocabulary <https://vocab.ices.dk/?ref=315>`_.

.. note::

   1. For conversion to Zarr files, call method ``.to_zarr()`` from
      the same ``Convert`` object as shown above.

   2. The ``Convert`` instance contains all the data unpacked from the
      raw file, so it is a good idea to clear it from memory once done with
      conversion.

.. note::
   The water level should be specified using ``dc.water_level = 'some value'``
   if the value is known. Otherwise, the water level will be saved as
   ``None`` if it is not already recorded by the instrument.


File access
-----------

Specifying multiple files
~~~~~~~~~~~~~~~~~~~~~~~~~

``Convert`` can accept a list of file paths pointing to multiple files. 
For example:

.. code-block:: python

   raw_file_paths = [
      './raw_data_files/file_01.raw',
      './raw_data_files/file_02.raw'
   ]
   dc = ep.Convert(raw_file_paths, model='EK60')

``Convert`` can also accept paths to files on remote systems such as ``http`` 
(a file on a web server) and cloud object storage such as Amazon Web Services (AWS) S3. 
This capability is provided by the `fsspec <https://filesystem-spec.readthedocs.io>`_ 
package, and all file systems implemented by ``fsspec`` are supported; 
a list of these file systems is available on the 
`fsspec registry documentation <https://filesystem-spec.readthedocs.io/en/latest/api.html#built-in-implementations>`_.

.. warning::
   ``fsspec``-based access from file locations other than a local file system was 
   introduced in version 0.5.0

https access
~~~~~~~~~~~~

A file on a web server can be accessed by specifying the file url:

.. code-block:: python

   raw_file_url = "https://mydomain.com/my/dir/D20170615-T190214.raw"
   ec = ep.Convert(raw_file_url, model='EK60')

AWS S3 access
~~~~~~~~~~~~~

.. note::

   These instructions should apply to other object storage providers such as 
   Google Cloud and Azure, but have only been tested on AWS S3.

A file on an AWS S3 "bucket" can be accessed by specifying the S3 path that starts
with "s3://" and using the ``storage_options`` argument. For a publicly accessible 
file ("anonymous") on a bucket called ``mybucket``:

.. code-block:: python

   raw_file_s3path = "s3://mybucket/my/dir/D20170615-T190214.raw"
   ec = ep.Convert(
      raw_file_s3path, model='EK60', 
      storage_options={'anon': True}
   )

If the file is not publicly accessible, the credentials can be specified explicitly
through ``storage_options`` keywords:

.. code-block:: python

   ec = ep.Convert(
      raw_file_s3path, model='EK60', 
      storage_options={key: 'ACCESSKEY', secret: 'SECRETKEY'}
   )

or via a credentials file stored in the default AWS credentials file 
(``~/.aws/credentials``). For ``profile`` "myprofilename" found in 
the credential file:

**NOTE: THIS NEEDS TO BE TESTED!**

.. code-block:: python

   import aiobotocore
   aws_session = aiobotocore.AioSession(profile='myprofilename')
   ec = ep.Convert(
      raw_file_s3path, model='EK60', 
      storage_options={'session': aws_session}
   )


File export
-----------

``Convert.to_netcdf()`` and ``Convert.to_zarr()`` accept 
convenient optional arguments. The examples below apply equally to
``Convert.to_netcdf()`` and ``Convert.to_zarr()``, except as noted.

**TODO:** Say something about the new default export directory, ``tmp_echopype_output`` (?)

Save converted files into another folder
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

By default the converted ``.nc`` and ``.zarr`` files are saved into 
the same folder as the input files. This can be changed by setting 
``save_path`` to a directory path.

.. code-block:: python

   raw_file_paths = [                                 # a list of raw data files
      './raw_data_files/dir1/file_01.raw',
      './raw_data_files/dir2/file_02.raw'
   ]
   ec = ep.Convert(raw_file_paths, model='EK60')      # create a Convert object
   ec.to_netcdf(save_path='./unpacked_files')         # set the output directory

In this example, each input file will be converted to an individual ``.nc`` file
and stored in the specified directory.

Combine multiple raw files into one converted file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   raw_file_paths = [                                 # a list of raw data files
      './raw_data_files/dir1/file_01.raw',
      './raw_data_files/dir2/file_02.raw'
   ]
   ec = ep.Convert(raw_file_paths, model='EK60')      # create a Convert object
   ec.to_zarr(
      combine=True,                                   # combine all input files when unpacking
      save_path='./unpacked_files/combined_file.zarr'
   )

``save_path`` has to be specified explicitly when combining multiple files.
If ``save_path`` is only a filename instead of a full path,
the combined output file will be saved in the same folder as the raw data files.

Save to AWS S3
~~~~~~~~~~~~~~

.. note::

   These instructions should apply to other object storage providers such as 
   Google Cloud and Azure, but have only been tested on AWS S3.

.. warning::
   Saving to S3 was introduced in version 0.5.0.

Converted files can be saved directly into an AWS S3 bucket by specifying ``storage_options``
as done with input files (see above, "AWS S3 access"). The example below illustrates a 
fully remote processing pipeline, reading raw files from a web server and saving the converted, 
combined zarr dataset to S3. Writing netCDF to S3 is currently not supported.

**TODO:** Add information about how to specify chunking and what the default chunking scheme is. 
Plus, this needs testing.


.. code-block:: python

      raw_file_urls = [
         'http://mydomain.com/from1/file_01.raw',
         'http://mydomain.com/from2/file_02.raw'
      ]
      ec = ep.Convert(raw_file_urls, model='EK60')
      ec.to_zarr(
         combine=True,
         overwrite=True,
         save_path='s3://mybucket/to/combined_file.zarr',
         storage_options={key: 'ACCESSKEY', secret: 'SECRETKEY'}
      )


Non-uniform data
----------------

Due to flexibility in echosounder settings, some dimensional parameters can
change in the middle of the file. For example:

- The maximum depth range to which data are collected can change in the middle
  of a data file in EK60. This happens often when the bottom depth changes.
- The sampling interval, which translates to temporal resolution, and thus range
  resolution, can also change in the middle of the file.
- Data from different frequency channels can also be collected with
  different sampling intervals.

These changes produce different number of samples along range (the ``range_bin``
dimension in the converted ``.nc`` file), which are incompatible with the goal
to save the data as a multi-dimensional array that can be easily indexed using xarray.

Echopype accommodates these cases in the following two ways:

1. When there are changes in the ``range_bin`` dimension in the middle of
   a data file, echopype creates separate files for each consecutive chunk of
   data with the same number of samples along range and append ``_partXX`` to
   the converted filename to indicate the existence of such changes.
   For example, if ``datafile.raw`` contains changes in the number of
   samples along range, the converted output will be ``datafile_part01.nc``,
   ``datafile_part02.nc``, etc.

2. When the number of samples along the ``range_bin`` dimensions are different
   for different frequency channels, echopype pads the shorter channels with
   ``NaN`` to form a multi-dimensional array. We use the data compression option
   in ``xarray.to_netcdf()`` and ``xarray.to_zarr()`` to avoid dramatically
   increasing the output file size due to padding.
