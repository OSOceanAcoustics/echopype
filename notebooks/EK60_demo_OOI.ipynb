{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Echosounder Data using `echopype`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we demonstrate how to process echosounder data using `echopype`.\n",
    "\n",
    "We pick data from the Ocean Observatories Initiative (OOI) [Oregon Offshore Cabled Shallow Profiler Mooring](https://oceanobservatories.org/site/ce04osps/) collected on August 21, 2017. This was the day of the solar eclipse, during which the reduced sunlight affected the regular diel vertical migration (DVM) patterns of marine life. This change was directly observed using a moored echosounder that happened to be within the totality zone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing one file\n",
    "Let's first test `echopype` by downloading and processing 1 file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install echopype**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install echopype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading the file\n",
    "!wget https://rawdata.oceanobservatories.org/files/CE04OSPS/PC01B/ZPLSCB102_10.33.10.143/OOI-D20170821-T163049.raw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'OOI-D20170821-T163049.raw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting from Raw to Standartized netCDF Format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import as part of a submodule\n",
    "from echopype.convert import Convert\n",
    "data_tmp = Convert(filename)\n",
    "data_tmp.raw2nc()\n",
    "os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calibrating, Denoising, Mean Volume Backscatter Strength**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from echopype.model import EchoData\n",
    "data = EchoData(filename[:-4]+'.nc')\n",
    "data.calibrate()     # calibration and echo-integration\n",
    "data.remove_noise()  # noise removal from calibrated Sv\n",
    "data.get_MVBS()      # obtain MVBS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.MVBS.MVBS.sel(frequency=200000).plot(x='ping_time',cmap = 'jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Multiple Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we verified that `echopype` does work, let's proceed to process all sonar data from August 21, 2017.\n",
    "\n",
    "To process multiple file from the OOI website we need to scrape the names of the existing files there. We will use the `Beautiful Soup` package for that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install --yes beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://rawdata.oceanobservatories.org/files/CE04OSPS/PC01B/ZPLSCB102_10.33.10.143/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = urlopen(path)\n",
    "soup = BeautifulSoup(response.read(), \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for item in soup.find_all(text=True):\n",
    "    if '.raw' in item:\n",
    "        urls.append(path+'/'+item)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [path+'/'+item for item in soup.find_all(text=True) if '.raw' in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify range, note that the data files were recorded at UTC time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '20170821-T06000'\n",
    "end_time = '20170822-T070000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the times to datetime format\n",
    "start_datetime = datetime.strptime(start_time,'%Y%m%d-T%H%M%S')\n",
    "end_datetime = datetime.strptime(end_time,'%Y%m%d-T%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check if a date is in the date range\n",
    "def in_range(date_str, start_time, end_time):\n",
    "    date_str = datetime.strptime(date_str,'%Y%m%d-T%H%M%S')\n",
    "    true = date_str >= start_datetime and date_str <= end_datetime\n",
    "    return(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the list of urls in range\n",
    "range_urls = []\n",
    "for url in urls: \n",
    "    date_str = url[-20:-4]\n",
    "    if in_range(date_str, start_time, end_time):\n",
    "        range_urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames = [url.split('//')[-1] for url in range_urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downloading the Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "rawnames = []\n",
    "for url in range_urls:\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    rawnames.append(url.split('//')[-1])\n",
    "    open(url.split('//')[-1], 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting from Raw to Standartized netCDF Format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import as part of a submodule\n",
    "from echopype.convert import Convert\n",
    "for filename in rawnames:\n",
    "    data_tmp = Convert(filename)\n",
    "    data_tmp.raw2nc()\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calibrating, Denoising, Mean Volume Backscatter Strength**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate and denoise\n",
    "from echopype.model import EchoData\n",
    "\n",
    "for filename in rawnames:\n",
    "    data = EchoData(filename[:-4]+'.nc')\n",
    "    data.calibrate()\n",
    "    data.remove_noise()\n",
    "    data.get_MVBS(save=True)\n",
    "    os.remove(filename[:-4]+'.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opening and Visualizing the Results in Parallel**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all files are in an appropriate format, we can open them and visualize them in parallel. For that we will need to install the `dask` parallelization library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install --yes dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = xr.open_mfdataset('*MVBS.nc',\n",
    "                        combine='by_coords',\n",
    "                        data_vars='different')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = res.range.sel(frequency=200000).max() - \\\n",
    "        res.range.sel(frequency=200000)\n",
    "MVBS_200k = res.MVBS.sel(frequency=200000).\\\n",
    "            sel(ping_time=slice('2017-08-21 07:00:00',\n",
    "                                '2017-08-22 07:00:00'))\n",
    "MVBS_200k.coords['depth'] = ('range_bin',depth)\n",
    "MVBS_200k = MVBS_200k.swap_dims({'range_bin': 'depth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MVBS_200k.plot(x='ping_time', y='depth',\n",
    "               vmin=-80, vmax=-30, cmap='jet',\n",
    "               size=5, aspect=3, yincrease=False)\n",
    "plt.xlabel('Ping time', fontsize=14)\n",
    "plt.ylabel('Depth (m)', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check solar radiation measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've seen how the echogram looks like during the day of eclipse, let's match the sonar observation with the solar radiation measurements.\n",
    "\n",
    "From the National Data Buoy Center (http://www.ndbc.noaa.gov/) we see that there is a surface buoy with a pyranometer that measures shortwave radiation (SRAD1 on the NDBC website) at the EAO site (Station 46098: http://www.ndbc.noaa.gov/station_page.php?station=46098). Let's access the data and check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import requests\n",
    "import urllib\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to construct the url to the historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srad_url = 'https://www.ndbc.noaa.gov/data/historical/srad/'\n",
    "filename = '46098'+'r'+'2017'+'.txt.gz'\n",
    "fileurl = srad_url+filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we open up the file and read all measurements from 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(urllib.request.urlopen(fileurl))\n",
    "lines = [line.decode().strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the first 5 columns are measurement timestamp, and the 6th column is the short wave radiation measurement. Let's now parse the entire 2017 data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srad1_time = []\n",
    "srad1 = []\n",
    "for line in lines[2:]:\n",
    "    line = line.split()\n",
    "    srad1_time.append(datetime.strptime(''.join(line[:5]), '%Y%m%d%H%M'))\n",
    "    nn = 5  # the 6th column is SRAD1\n",
    "    srad1.append(np.nan if line[nn] == '9999.0' else float(line[nn]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make it into a pandas DataFrame for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_srad = pd.DataFrame(srad1, columns=['SRAD'], index=srad1_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOw we can see how the solar radiation changed during the time of eclipse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_srad[np.logical_and(df_srad.index>=pd.to_datetime('2017-08-21 07:00:00'), \n",
    "                       df_srad.index<=pd.to_datetime('2017-08-22 07:00:00'))].\\\n",
    "        plot(logy=True, color='r', figsize=(12,3))\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is indeed a sharp drop around the time of eclipse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine sonar observation with solar radiation measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally put everything together and figure out the effect of eclipse on the marine animals!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax0 = plt.subplot2grid((3, 1), (0, 0))\n",
    "ax1 = plt.subplot2grid((3, 1), (1, 0),rowspan=2)\n",
    "\n",
    "df_srad[np.logical_and(df_srad.index>=pd.to_datetime('2017-08-21 07:00:00'), \n",
    "                       df_srad.index<=pd.to_datetime('2017-08-22 07:00:00'))].plot(ax=ax0, logy=True, color='r')\n",
    "ax0.set_ylabel('Radiation (W/m^2)', fontsize=14)\n",
    "\n",
    "MVBS_200k.plot(x='ping_time', y='depth',\n",
    "               ax=ax1, vmin=-80, vmax=-30, cmap='jet',\n",
    "               yincrease=False, add_colorbar=False)\n",
    "plt.subplots_adjust(hspace = 0.14)\n",
    "plt.xlabel('Ping time (UTC)', fontsize=14)\n",
    "plt.ylabel('Depth (m)', fontsize=14)\n",
    "\n",
    "plt.title('')\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%b-%d %H:%M'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look how the dip at solar radiataion reading matches exactly with the upwarding moving blip at UTC 10:21. The animals were fooled by the temporary mask of the sun and thought it's getting dark as at dusk!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
